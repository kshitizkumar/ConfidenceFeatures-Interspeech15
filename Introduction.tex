Automatic speech recognition (ASR) has seen the strongest wave of deployment and usage across devices and services in recent years. Confidence-scores are integral to ASR, we obtain these scores from a confidence-classifier trained over a set of confidence-features to maximally discriminate between correct and incorrect recognitions. We refer \cite{Posen1} for an introduction to our confidence classifier framework. The Confidence-scores that lie in a [0,1] range, we desire higher scores for correct recognitions, and lower for, (a) incorrect recognitions from in-grammar (IG) and, (b) any recognition from out-of-grammar (OOG) utterances. These scores are typically evaluated for individual words as well as the utterance. Historically confidences were used for ASR-enabled devices that are always in an active (continuously) listening mode in an application-constrained grammar. There potential recognitions from side-speech, background noise etc. can trigger unexpected system response. Therefore, confidence-scores were used to contain recognitions from OOG utterances from being recognized as IG utterances. We refer \cite{CMsurvey_Jiang_SpeechCommunication06, Blatz04confidenceestimation,Rose_UV_1995,Mathan_Rejection_1991,Sukkar_UV_1996} for a survey of confidence techniques and confidence-features. We refer \cite{Chase_wordand} for a description of confidence-features obtained from decoding process, they also presented an analysis of the features with respect to reduction in cross-entropy criterion. Confidence-scores were computed from word lattices in \cite{WordLattice_Kemp_Eurospeech97}, and N-best lists in \cite{rueber1997obtaining}. We also refer~\cite{MaximumEntropyConfidence_White_ICASSP07, NBest_Wessel_Eurospeech99, Wessel01ney,Weintraub97} for classifiers and additional features used for confidence-classification task.

Confidence-scores have also been used in other ASR applications \emph{e.g.}, (a) arbitration where we select the best between client and service recognition results, (b) recognizer output voting error reduction (ROVER) where we perform multi-system combination \cite{hillard2007rover,NistRover}, (c) selecting high quality data for unsupervised model training, (d) key-word spotting tasks, (e) confidence-normalization \cite{kumar2014normalization} etc. While many of the downstream ASR applications consume confidence-scores, we have seen limited attempts on consuming confidence-features instead of confidence-score. Using confidence-features in downstream applications offers many advantages, (a) access to detailed information, (b) opportunity to retrain with confidence-features and optimize downstream task, (c) downstream application may operate over a dataset where confidence-score may not be applicable, (d) confidence-features are usually robust across languages but confidence-score may require normalization \cite{kumar2014normalization}, (e) updating confidence-classifier does not create a dependency on updating downstream application. In this work we present our individual confidence-features, and, highlight the diverse information they encapsulate. We specifically demonstrate the richness of these features for arbitration application where we present significant gains in arbitration metric. 

In addition to emphasizing the importance of confidence-features, we present a novel application of confidence-scores by embedding them in DNN speaker adaptation framework. We have established significant gains with our current speaker adaptation ~\cite{XueSVDAdaptation}, there incorporating confidence-scores in adaptation provides additional gains. Rest of this work is organized in the following. We provide a background to our confidence-features and confidence-scores in Sec.~\ref{Sec:CC-Background}. We discuss an application of these features to arbitration in Sec.~\ref{Sec:Arbitration}. We present a new application of confidence-scores to further improve our baseline DNN adaptation \cite{XueSVDAdaptation} in Sec.~\ref{Sec:Adaptation}. We discuss  new scopes and applications of confidence-features and scores in Sec.~\ref{Sec:Discussion}. Sec.~\ref{Sec:Conclusion} concludes our study.