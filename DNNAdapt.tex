In this sec. we present a new application of confidence-scores in the DNN adaptation framework. We have huge gains in WER across many scenarios with the deployment of DNNs but we have also established that speaker adaptation of DNN models provides a significant scope for further improvements. In this section, we present our baseline speaker adaptation approach and propose to additionally include confidence-scores in speaker adaptation with limited and large adaptation data scenarios. We have noted that confidence-scores imply the correctness of recognition results. In the context of speaker-adaptation confidence-scores also indicate a degree of match between the speaker-dependent data and speaker-independent model, thus smaller confidence-scores imply weaker match between data and model. So we can leverage confidence-score in the DNN speaker adaptation optimization by disproportionately weighting optimization criterion across data based on their confidence-scores. We create a new recipe where we collect adaptation data into 3 buckets depending on low, medium and high confidence-scores. Our goal is to change the optimization metric by including confidence-scores. Corresponding to the 3 confidence-categories we can weight the data samples from those categories according to specified values for those categories.

We know that confidence can indicate a great deal about the quality of utterances that we use in adaptation but none of the current adaptation recipes include confidence, specifically: for incorrect hypothesis, (a) low confidence data is a poor match to model and may benefit with higher weight on the data, (b) low confidence results are likely to be incorrect, so we should deemphasize these utterances, (c) high confidence data is already a good match to model, so there is less to learn from that data, (d) high confidence results are likely to be correct, so we should emphasize these utterances.

For 50 utts we can improve WERR from 11.6\% to 14.1\% for supervised adaptation.

Applied this recipe to training and testing on 6 speaker adaptation data on SMD task
Based on experiments selected a recipe that simply duplicates the low and medium confidence buckets while retaining the high confidence bucket. Noting results for unsupervised and supervised adaptation in below

\subsection{DNN adaptation experiment}
Training vs test Dataset
Server task
Large LM
Any difference of above 1\% relative is significant.



\begin{table}
\begin{center}
\begin{small}
\caption{WER for Supervised adaptation. Baseline WER is 19.9\%.} \label{tab:mean-FA-diff}
\begin{tabular}{|c|c|c|c|c|c|}
\hline
Nutts &  \multicolumn{2}{|c|}{Best Adaptation} & \multicolumn{2}{|c|}{+Include} \\
&  \multicolumn{2}{|c|}{ }  & \multicolumn{2}{|c|}{Confidence-Score} \\
\hline
 &   WER & WERR & WER & WERR\\
\hline
20 &  19.6  & 1.5  & 18.9 & 5.0\\
50 &  17.6  & 11.6  & 17.1 & 14.1\\
100 &  16.7  & 16.1  & 16.4 & 17.6\\
\hline
\end{tabular}
\end{small}
\end{center}
\end{table}

\begin{table}
\begin{center}
\begin{small}
\caption{WER for Unsupervised adaptation. Baseline WER is 19.9\%.} \label{tab:mean-FA-diff}
\begin{tabular}{|c|c|c|c|c|c|}
\hline
Nutts &  \multicolumn{2}{|c|}{Best Adaptation} & \multicolumn{2}{|c|}{+Include} \\
&  \multicolumn{2}{|c|}{ }  & \multicolumn{2}{|c|}{Confidence-Score} \\
\hline
 &   WER & WERR & WER & WERR\\
\hline
20 &  20.2  & -1.4  & 19.9 & 0.2\\
50 &  19.0  & 4.9  & 18.2 & 8.5\\
100 &  18.0  & 9.8  & 17.7 & 11.3\\
\hline
\end{tabular}
\end{small}
\end{center}
\end{table}
