%Recent successes in adopting DNNs have achieved great success across various scenarios and datasets in speech recognition. 
In~\cite{XueSVDAdaptation}, we established that speaker adaption techniques can provide significant improvements to state-of-the-art DNNs-based ASR. There, we also proposed singular-value-decomposition (SVD) bottleneck adaptation, this technique involves much less adaptation parameters, while providing significant accuracy improvement.
In this section we propose to embed confidence-scores in DNN adaptation. We noted that confidence-scores imply the correctness of recognition results. In the context of speaker-adaptation confidence-scores indicate a degree of match between the speaker-specific data and speaker-independent (SI) model, thus smaller confidence-scores imply weaker match between data and model, so speaker adaptation can benefit with emphasizing data with low confidence-scores. We propose to include a weight $c(x_t)$ to standard negative cross entropy criterion ~\cite{rumelhart1988learning} in below:
%We leverage confidence-scores in adaptation by weighting data with corresponding confidence-score in DNN optimization.

\begin{equation}
D = \frac{1}{N} \sum_{t=1}^{N}c(x_t)\sum_{s_t=1}^{S} \tilde{p}(s_t|x_t) \log p(s_t|x_t)
\end{equation}
There for frame $t$, $x_t$ indicates input vector to DNN. Our proposed weights $c(x_t)$ depend on the confidence-scores associated with feature $x_t$. We group all adaptation data into 3 categories based on low, medium and high confidence-scores. We specify $c(x_t)$=$2$ for data associated with low confidence scores, and retain $c(x_t)$=$1$ for data associated with medium and high confidence-scores. In general we can specify other appropriate values for $c(x_t)$, though we found that above values of $c(x_t)$ provided consistently strong performance. Note that the baseline that doesn't embed confidence-scores is equivalent to retaining $c(x_t)$=$1$ for all data.

\subsection{DNN adaptation experiment}
We evaluated our approach on short message dictation (SMD) task and applied SVD bottleneck adaptation. The baseline SI models were trained with 300 hours VS and SMD data. Our core features are 66-dim dynamic Log-Mel-Filterbank features. We use a context window of 11 frames for a total of 726-dim input vector to DNN that has 5 hidden layers with 2,048 nodes each. The output layer has 6000 nodes. Additional details on the experimental setup can be seen in \cite{XueSVDAdaptation}. Our test set consisted of a SMD task with 6 speakers. The total number of test set words is 20,203. The baseline low-rank SI system achieves 19.93\% word-error rate (WER); we also obtained confidence-scores by decoding against SI model. We varied the number of adaptation utterances from 20 (2.2 minutes) to 100 (11 minutes) for each speaker. 

We note results for supervised adaptation using ground-truth transcriptions in Table~\ref{tab:sup-WER}. There for 20 utts.~adaptation data we double the word-error rate relative reduction (WERR) from 1.5\% to 5\% when including confidence-scores in adaptation with $c(x_t)$=$2$ for low confidence data, and otherwise $c(x_t)$=$1$. We also experimented with emphasizing medium and high confidence data, and few other combinations but we found that above values of $c(x_t)$ provided consistently better results. This is understandable as here we are emphasizing DNN to learn from data that is currently a weaker match to the SI model. Medium and high confidence data is already a good match to model, so we may not learn a lot by emphasizing those data segments. Confidence-scores have also been for data selection~\cite{zhang2014semi} and model training in \cite{gollan2008confidence} but the focus was mostly on data with high confidence; our results provide a new dimension to the use of confidence-scores where we emphasize data with low confidence-scores. In Table~\ref{tab:sup-WER}, we also see strong gains for 50 and 100 utts. adaptation data. A difference of 1\% WERR is significant in this task. 

We report results for unsupervised adaptation in Table.~\ref{tab:unsup-WER}, there we decode data against SI model and use hypothesis to align data for adaptation. There too we see 1.4-3.6\% increase in WERR across different utterances. Using 20 utterances regresses baseline unsupervised adaptation, but we at least retain performance when using confidence-scores. Low confidence data from hypothesis may also indicate, (1) lower accuracy along with, (2) weaker match to SI model. However, we find merit with emphasizing low confidence data, this indicates that out of the above two factors, weaker match to SI model dominates.

% We also know that confidence can indicate a great deal about the quality of utterances that we use in adaptation but none of the current adaptation recipes include confidence, specifically: for incorrect hypothesis, (a) low confidence data is a poor match to model and may benefit with higher weight on the data, (b) low confidence results are likely to be incorrect, so we should deemphasize these utterances, (c) high confidence data is already a good match to model, so there is less to learn from that data, (d) high confidence results are likely to be correct, so we should emphasize these utterances.





\begin{table}
\begin{center}
\begin{small}
\caption{WER and WERR for Supervised adaptation. Baseline WER is 19.9\%.} \label{tab:sup-WER}
\begin{tabular}{|c|c|c|c|c|c|}
\hline
Nutts &  \multicolumn{2}{|c|}{Best Adaptation} & \multicolumn{2}{|c|}{+Include} \\
&  \multicolumn{2}{|c|}{ }  & \multicolumn{2}{|c|}{Confidence-Score} \\
\hline
 &   WER & WERR & WER & WERR\\
\hline
20 &  19.6  & 1.5  & 18.9 & 5.0\\
50 &  17.6  & 11.6  & 17.1 & 14.1\\
100 &  16.7  & 16.1  & 16.4 & 17.6\\
\hline
\end{tabular}
\end{small}
\end{center}
\end{table}

\begin{table}
\begin{center}
\begin{small}
\caption{WER and WERR for Unsupervised adaptation. Baseline WER is 19.9\%.} \label{tab:unsup-WER}
\begin{tabular}{|c|c|c|c|c|c|}
\hline
Nutts &  \multicolumn{2}{|c|}{Best Adaptation} & \multicolumn{2}{|c|}{+Include} \\
&  \multicolumn{2}{|c|}{ }  & \multicolumn{2}{|c|}{Confidence-Score} \\
\hline
 &   WER & WERR & WER & WERR\\
\hline
20 &  20.2  & -1.4  & 19.9 & 0.0\\
50 &  19.0  & 4.9  & 18.2 & 8.5\\
100 &  18.0  & 9.8  & 17.7 & 11.3\\
\hline
\end{tabular}
\end{small}
\end{center}
\end{table}
