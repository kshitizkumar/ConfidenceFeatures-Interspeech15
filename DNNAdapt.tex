% In this section, we present a new application of confidence-scores in the DNN adaptation framework. 
Recent successes in adopting CD-DNN-HMMs have achieved great success across various scenarios and datasets in speech recognition. Despite the advances by DNNs, we have also established that the development of speaker adaption techniques for CD-DNN-HMMs provides a significant scope for further improvements. 
In \cite{xue-2014}, we have proposed the SVD bottleneck adaptation by adapting all the linear bottleneck layers in the SVD-restructured model. This technique involves much less adaptation parameters, while providing significant accuracy improvement.
In this section, we propose to additionally include confidence-scores in speaker adaptation with limited and large adaptation data scenarios. We have noted that confidence-scores imply the correctness of recognition results. In the context of speaker-adaptation confidence-scores also indicate a degree of match between the speaker-dependent data and speaker-independent model, thus smaller confidence-scores imply weaker match between data and model. So we can leverage confidence-score in the DNN speaker adaptation optimization by disproportionately weighting optimization criterion across data based on their confidence-scores. We create a new recipe where we collect adaptation data into 3 buckets depending on low, medium and high confidence-scores. Our goal is to change the optimization metric by including confidence-scores. Corresponding to the 3 confidence-categories we can weight the data samples from those categories according to specified values for those categories.

We know that confidence can indicate a great deal about the quality of utterances that we use in adaptation but none of the current adaptation recipes include confidence, specifically: for incorrect hypothesis, (a) low confidence data is a poor match to model and may benefit with higher weight on the data, (b) low confidence results are likely to be incorrect, so we should deemphasize these utterances, (c) high confidence data is already a good match to model, so there is less to learn from that data, (d) high confidence results are likely to be correct, so we should emphasize these utterances.

For 50 utts we can improve WERR from 11.6\% to 14.1\% for supervised adaptation.

Applied this recipe to training and testing on 6 speaker adaptation data on SMD task
Based on experiments selected a recipe that simply duplicates the low and medium confidence buckets while retaining the high confidence bucket. Noting results for unsupervised and supervised adaptation in below

\subsection{DNN adaptation experiment}
The proposed adaptation method was evaluated on short message dictation (SMD) tasks and compared with the SVD bottleneck adaptation.
The baseline SI models were trained with 300 hours VS and SMD data. The input feature to CD-DNN-HMM system is a 24-dimension mean-normalized log-filter bank feature with up to second-order derivatives and a context window of 11 frames, forming a vector of 792-dimension ($72 \times 11$) input. On top of the input layer there are 5 hidden layers with 2,048 units for each. The output layer has a dimension of 5,976.
We convert the full-rank DNN model to low-rank model by doing SVD on all the matrices except the one between the input and the first hidden layer, and keep 40\% of total singular values. The numbers of units on the linear layers after SVD are 208, 184, 176, 200, and 344 accordingly, from bottom to top. We then retrained the low-rank model and obtained comparable accuracy to the full-rank model. More details of SVD based low-rank DNN model training can be found in \cite{xue-2013}.

The initial experiments were conducted on a SMD task which consists of 7 speakers.
The total number of test set words is 20,203. There is no overlap among the development and test data.
The baseline low-rank SI system achieves 21.43\% WER averaged on 7 speakers.
The DNN models are adapted in both supervised and unsupervised way, where the SI model is used to decode and align the development data.
We varied the number of adaptation utterances from 5 (32 seconds) to 200 (22 minutes) for each speaker.

Any difference of above 1\% relative is significant.



\begin{table}
\begin{center}
\begin{small}
\caption{WER for Supervised adaptation. Baseline WER is 19.9\%.} \label{tab:mean-FA-diff}
\begin{tabular}{|c|c|c|c|c|c|}
\hline
Nutts &  \multicolumn{2}{|c|}{Best Adaptation} & \multicolumn{2}{|c|}{+Include} \\
&  \multicolumn{2}{|c|}{ }  & \multicolumn{2}{|c|}{Confidence-Score} \\
\hline
 &   WER & WERR & WER & WERR\\
\hline
20 &  19.6  & 1.5  & 18.9 & 5.0\\
50 &  17.6  & 11.6  & 17.1 & 14.1\\
100 &  16.7  & 16.1  & 16.4 & 17.6\\
\hline
\end{tabular}
\end{small}
\end{center}
\end{table}

\begin{table}
\begin{center}
\begin{small}
\caption{WER for Unsupervised adaptation. Baseline WER is 19.9\%.} \label{tab:mean-FA-diff}
\begin{tabular}{|c|c|c|c|c|c|}
\hline
Nutts &  \multicolumn{2}{|c|}{Best Adaptation} & \multicolumn{2}{|c|}{+Include} \\
&  \multicolumn{2}{|c|}{ }  & \multicolumn{2}{|c|}{Confidence-Score} \\
\hline
 &   WER & WERR & WER & WERR\\
\hline
20 &  20.2  & -1.4  & 19.9 & 0.2\\
50 &  19.0  & 4.9  & 18.2 & 8.5\\
100 &  18.0  & 9.8  & 17.7 & 11.3\\
\hline
\end{tabular}
\end{small}
\end{center}
\end{table}
