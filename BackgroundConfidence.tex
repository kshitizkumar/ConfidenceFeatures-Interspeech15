We discussed the significance of confidence-scores in Section~\ref{Sec:Intro} where we mentioned that confidence-classifier makes an inference on the correctness of recognition events. This is thus a binary classification problem \cite{Bishop} with the 2-classes in (1) correct recognitions, (2) all incorrect recognitions that includes misrecognitions over IG utterances as well any recognition from OOG utterances. The classifier is trained from a rich set of confidence-features that we obtain from speech decoding.
A few of our prominent confidence-features are:
\begin{enumerate}
  \item acoustic-model features - we aggregate per-frame acoustic score over a word or an utterance. We also compute scores from acoustic-arc transitions. These scores are typically normalized for duration.
  \item language-model features - these include fanout and perplexity features.
  \item noise and silence-model features - we compute features from noise and silence models.
  \item 2nd-order features - we compute word-confidence-weighted average of acoustic features in a phrase, see \cite{Posen1}.
  \item duration features - we compute word-duration and number of words in a phrase etc.
  \item senone count - count of active senones during decoding.
  \item confusibility - this indicates confusibility of the best hypothesis.
  \item log-spectra-derived features - we derive posterior features from speech log-Melspectra.
\end{enumerate}
Our features are appropriately normalized to be robust across speech duration and intensity. We refer \cite{Posen1} for additional details on our confidence-classifier architecture and related features.  Confidence-scores are computed from a confidence-classifier trained over confidence-features. These features are obtained from a particular collection of training data and grammar; we obtain positive tokens from successfully recognized utterances and negatives from incorrect recognitions. 

% Though a number of speech applications consume confidence-scores, we have seen limited attempts on directly consuming the rich set of confidence-features in those applications.

Confidence-scores are optimized for classifying correct and incorrect recognitions. The optimization criterion and corresponding needs can be different for downstream speech applications that currently consume confidence-scores. In this work we motivate a use case for rich set of confidence-features. These features are typically 20-dim for a word or for an utterance, so additional memory required to store these features is minimal. The confidence-features are already computed for evaluating confidence-score so additional work required to extract confidence-features is minimal. The only incremental cost is to communicate confidence-features to the downstream application. Considering a typical speech segment of 4 secs. encoded at 8~kB/sec for a total of 32kB, confidence-features just add 80 Bytes to the communication footprint, thus less than 0.2\% to speech footprint.
